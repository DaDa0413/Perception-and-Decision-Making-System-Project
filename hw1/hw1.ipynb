{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7ab083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "print(o3d.__version__)\n",
    "file_path = 'Data_collection/first_floor/'\n",
    "image_number = 189\n",
    "first_image = 0\n",
    "voxel_size = 0.002\n",
    "threshold = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d632a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "#     print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "#     print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "#     print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f129ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(image, voxel_size):\n",
    "    # Create target point cloud\n",
    "    file_name = '{:04d}'.format(image)\n",
    "    pcd = o3d.io.read_point_cloud(file_path + \"pcd/\" + file_name + \".pcd\")\n",
    "\n",
    "#     print(\":: Load target point cloud and disturb initial pose.\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "#     source.transform(trans_init)\n",
    "\n",
    "    # Extract fpfh\n",
    "    pcd_down, pcd_fpfh = preprocess_point_cloud(pcd, voxel_size)\n",
    "    return pcd, pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb26ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global ICP\n",
    "# RANSAC registration\n",
    "def execute_global_registration(source, target, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "#     print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "#     print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "#     print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06126a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target point cloud\n",
    "\n",
    "target, target_down, target_fpfh = prepare_dataset(first_image, voxel_size)\n",
    "aggr_pcd = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0c9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic: 0001\n",
      "Pic: 0002\n",
      "Pic: 0003\n",
      "Pic: 0004\n",
      "Pic: 0005\n",
      "Pic: 0006\n",
      "Pic: 0007\n",
      "Pic: 0008\n",
      "Pic: 0009\n",
      "Pic: 0010\n",
      "Pic: 0011\n",
      "Pic: 0012\n",
      "Pic: 0013\n",
      "Pic: 0014\n",
      "Pic: 0015\n",
      "Pic: 0016\n",
      "Pic: 0017\n",
      "Pic: 0018\n",
      "Pic: 0019\n",
      "Pic: 0020\n",
      "Pic: 0021\n",
      "Pic: 0022\n",
      "Pic: 0023\n",
      "Pic: 0024\n",
      "Pic: 0025\n",
      "Pic: 0026\n",
      "Pic: 0027\n",
      "Pic: 0028\n",
      "Pic: 0029\n",
      "Pic: 0030\n",
      "Pic: 0031\n",
      "Pic: 0032\n",
      "Pic: 0033\n",
      "Pic: 0034\n",
      "Pic: 0035\n",
      "Pic: 0036\n",
      "Pic: 0037\n",
      "Pic: 0038\n",
      "Pic: 0039\n",
      "Pic: 0040\n",
      "Pic: 0041\n",
      "Pic: 0042\n",
      "Pic: 0043\n",
      "Pic: 0044\n",
      "Pic: 0045\n",
      "Pic: 0046\n",
      "Pic: 0047\n",
      "Pic: 0048\n",
      "Pic: 0049\n",
      "Pic: 0050\n",
      "Pic: 0051\n",
      "Pic: 0052\n",
      "Pic: 0053\n",
      "Pic: 0054\n",
      "Pic: 0055\n",
      "Pic: 0056\n",
      "Pic: 0057\n",
      "Pic: 0058\n",
      "Pic: 0059\n",
      "Pic: 0060\n",
      "Pic: 0061\n",
      "Pic: 0062\n",
      "Pic: 0063\n",
      "Pic: 0064\n",
      "Pic: 0065\n",
      "Pic: 0066\n",
      "Pic: 0067\n",
      "Pic: 0068\n",
      "Pic: 0069\n",
      "Pic: 0070\n",
      "Pic: 0071\n",
      "Pic: 0072\n",
      "Pic: 0073\n",
      "Pic: 0074\n",
      "Pic: 0075\n",
      "Pic: 0076\n",
      "Pic: 0077\n",
      "Pic: 0078\n",
      "Pic: 0079\n",
      "Pic: 0080\n",
      "Pic: 0081\n",
      "Pic: 0082\n",
      "Pic: 0083\n",
      "Pic: 0084\n",
      "Pic: 0085\n",
      "Pic: 0086\n",
      "Pic: 0087\n",
      "Pic: 0088\n",
      "Pic: 0089\n",
      "Pic: 0090\n",
      "Pic: 0091\n",
      "Pic: 0092\n",
      "Pic: 0093\n",
      "Pic: 0094\n",
      "Pic: 0095\n",
      "Pic: 0096\n",
      "Pic: 0097\n",
      "Pic: 0098\n",
      "Pic: 0099\n",
      "Pic: 0100\n",
      "Pic: 0101\n",
      "Pic: 0102\n",
      "Pic: 0103\n",
      "Pic: 0104\n",
      "Pic: 0105\n",
      "Pic: 0106\n",
      "Pic: 0107\n",
      "Pic: 0108\n",
      "Pic: 0109\n",
      "Pic: 0110\n",
      "Pic: 0111\n",
      "Pic: 0112\n",
      "Pic: 0113\n",
      "Pic: 0114\n",
      "Pic: 0115\n",
      "Pic: 0116\n",
      "Pic: 0117\n",
      "Pic: 0118\n",
      "Pic: 0119\n",
      "Pic: 0120\n",
      "Pic: 0121\n",
      "Pic: 0122\n",
      "Pic: 0123\n",
      "Pic: 0124\n",
      "Pic: 0125\n",
      "Pic: 0126\n",
      "Pic: 0127\n",
      "Pic: 0128\n",
      "Pic: 0129\n",
      "Pic: 0130\n",
      "Pic: 0131\n",
      "Pic: 0132\n",
      "Pic: 0133\n",
      "Pic: 0134\n",
      "Pic: 0135\n",
      "Pic: 0136\n",
      "Pic: 0137\n",
      "Pic: 0138\n",
      "Pic: 0139\n",
      "Pic: 0140\n",
      "Pic: 0141\n",
      "Pic: 0142\n",
      "Pic: 0143\n",
      "Pic: 0144\n",
      "Pic: 0145\n",
      "Pic: 0146\n",
      "Pic: 0147\n",
      "Pic: 0148\n",
      "Pic: 0149\n",
      "Pic: 0150\n",
      "Pic: 0151\n",
      "Pic: 0152\n",
      "Pic: 0153\n",
      "Pic: 0154\n",
      "Pic: 0155\n",
      "Pic: 0156\n",
      "Pic: 0157\n",
      "Pic: 0158\n",
      "Pic: 0159\n",
      "Pic: 0160\n",
      "Pic: 0161\n",
      "Pic: 0162\n",
      "Pic: 0163\n",
      "Pic: 0164\n",
      "Pic: 0165\n",
      "Pic: 0166\n",
      "Pic: 0167\n",
      "Pic: 0168\n",
      "Pic: 0169\n",
      "Pic: 0170\n",
      "Pic: 0171\n",
      "Pic: 0172\n",
      "Pic: 0173\n",
      "Pic: 0174\n",
      "Pic: 0175\n",
      "Pic: 0176\n",
      "Pic: 0177\n",
      "Pic: 0178\n",
      "Pic: 0179\n",
      "Pic: 0180\n",
      "Pic: 0181\n",
      "Pic: 0182\n",
      "Pic: 0183\n",
      "Pic: 0184\n",
      "Pic: 0185\n",
      "Pic: 0186\n",
      "Pic: 0187\n",
      "Pic: 0188\n",
      "Pic: 0189\n"
     ]
    }
   ],
   "source": [
    "# Transform all the pic\n",
    "transformations = []\n",
    "trajectories = []\n",
    "trajectories.append([0,0,0,1])\n",
    "\n",
    "for index in range(first_image + 1, image_number + 1):\n",
    "    print(\"Pic: {0:04d}\".format(index))\n",
    "    # Load point cloud and preprocessing\n",
    "    source, source_down, source_fpfh = prepare_dataset(index, voxel_size)\n",
    "    \n",
    "    # Global registration\n",
    "    result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "    trans_init = result_ransac.transformation\n",
    "    # Local registration\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source_down, target_down, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "\n",
    "    # Update the transformations list and transform the current pcd to G_0\n",
    "    transformations.append(reg_p2p.transformation)\n",
    "    t = np.identity(4)\n",
    "    for trans in transformations:\n",
    "        t = np.dot(t, trans)\n",
    "    # transofrm the source to G_0\n",
    "    s = copy.deepcopy(source)\n",
    "    s.transform(t)\n",
    "    # Trajectory\n",
    "    transition = np.append(reg_p2p.transformation[0:3,3], 1)\n",
    "    trajectories.append(np.dot(t, transition))\n",
    "    # Aggregate the result\n",
    "    aggr_pcd += s\n",
    "    \n",
    "    target = source\n",
    "    target_down = source_down\n",
    "    target_fpfh = source_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "aggr_pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "aggr_pcd_down = aggr_pcd.voxel_down_sample(voxel_size / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b930fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([aggr_pcd_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46e76839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the roof\n",
    "no_roof_pcd = copy.deepcopy(aggr_pcd_down)\n",
    "pts = np.asarray(no_roof_pcd.points)\n",
    "crs = np.asarray(no_roof_pcd.colors)\n",
    "valid = pts[:,1] < 0\n",
    "\n",
    "no_roof_pcd.points = o3d.utility.Vector3dVector(pts[valid])\n",
    "no_roof_pcd.colors = o3d.utility.Vector3dVector(crs[valid])\n",
    "# o3d.visualization.draw_geometries([no_roof_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5ef48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "lines = []\n",
    "line_index = 1\n",
    "\n",
    "with open(file_path + \"GT_pose.txt\", \"r\") as fp:\n",
    "    line= fp.readline()\n",
    "    x, y, z, rw, rx, ry, rz= line.split(\" \")\n",
    "    x0 = float(x) \n",
    "    y0 = float(y)\n",
    "    z0 = float(z)\n",
    "    points.append([(x0 - x0), (y0 - y0), (z0 - z0)])\n",
    "    line= fp.readline()\n",
    "    while line:\n",
    "        x, y, z, rw, rx, ry, rz= line.split(\" \")\n",
    "        x = float(x) - x0\n",
    "        y = float(y) - y0\n",
    "        z = float(z) - z0\n",
    "        points.append([x*0.0255, y*0.0255, z*0.0255])\n",
    "        lines.append([line_index - 1, line_index])\n",
    "        line_index += 1\n",
    "        line = fp.readline()\n",
    "fp.close()\n",
    "\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "gt_line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "gt_line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([gt_line_set, no_roof_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94647d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "lines = []\n",
    "line_index = 0\n",
    "# points.append(p)\n",
    "for tra in trajectories:\n",
    "    # multiply by transformation\n",
    "    tra = np.dot([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]], tra)\n",
    "    points.append(tra[0:3])\n",
    "    lines.append([line_index, line_index + 1])\n",
    "    line_index += 1\n",
    "del lines[-1]\n",
    "\n",
    "colors = [[0, 0, 1] for i in range(len(lines))]\n",
    "icp_line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "icp_line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([icp_line_set, no_roof_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f80c7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([gt_line_set, icp_line_set, no_roof_pcd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat2",
   "language": "python",
   "name": "habitat2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
