{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7ab083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "print(o3d.__version__)\n",
    "file_path = 'Data_collection/second_floor/'\n",
    "image_number = 68\n",
    "first_image = 0\n",
    "voxel_size = 0.002\n",
    "threshold = 0.002  / 1000000\n",
    "max_iteration = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d632a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "#     print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "#     print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "#     print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f129ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(image, voxel_size):\n",
    "    # Create target point cloud\n",
    "    file_name = '{:04d}'.format(image)\n",
    "    pcd = o3d.io.read_point_cloud(file_path + \"pcd/\" + file_name + \".pcd\")\n",
    "\n",
    "#     print(\":: Load target point cloud and disturb initial pose.\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "#     source.transform(trans_init)\n",
    "\n",
    "    # Extract fpfh\n",
    "    pcd_down, pcd_fpfh = preprocess_point_cloud(pcd, voxel_size)\n",
    "    return pcd, pcd_down, pcd_fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb26ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global ICP\n",
    "# RANSAC registration\n",
    "def execute_global_registration(source, target, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "#     print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "#     print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "#     print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source, target, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06126a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target point cloud\n",
    "\n",
    "target, target_down, target_fpfh = prepare_dataset(first_image, voxel_size)\n",
    "aggr_pcd = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0c9f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic: 0001\n",
      "Pic: 0002\n",
      "Pic: 0003\n",
      "Pic: 0004\n",
      "Pic: 0005\n",
      "Pic: 0006\n",
      "Pic: 0007\n",
      "Pic: 0008\n",
      "Pic: 0009\n",
      "Pic: 0010\n",
      "Pic: 0011\n",
      "Pic: 0012\n",
      "Pic: 0013\n",
      "Pic: 0014\n",
      "Pic: 0015\n",
      "Pic: 0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniellin/anaconda3/envs/habitat/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/daniellin/anaconda3/envs/habitat/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/daniellin/anaconda3/envs/habitat/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/daniellin/Documents/habitat/hw1/files_of_ta/registration.py:59: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return indxSum/np.size(index,0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic: 0017\n",
      "Pic: 0018\n",
      "Pic: 0019\n",
      "Pic: 0020\n",
      "Pic: 0021\n",
      "Pic: 0022\n",
      "Pic: 0023\n",
      "Pic: 0024\n",
      "Pic: 0025\n",
      "Pic: 0026\n",
      "Pic: 0027\n",
      "Pic: 0028\n",
      "Pic: 0029\n",
      "Pic: 0030\n",
      "Pic: 0031\n",
      "Pic: 0032\n",
      "Pic: 0033\n",
      "Pic: 0034\n",
      "Pic: 0035\n",
      "Pic: 0036\n",
      "Pic: 0037\n",
      "Pic: 0038\n",
      "Pic: 0039\n",
      "Pic: 0040\n",
      "Pic: 0041\n",
      "Pic: 0042\n",
      "Pic: 0043\n",
      "Pic: 0044\n",
      "Pic: 0045\n",
      "Pic: 0046\n",
      "Pic: 0047\n",
      "Pic: 0048\n",
      "Pic: 0049\n",
      "Pic: 0050\n",
      "Pic: 0051\n",
      "Pic: 0052\n",
      "Pic: 0053\n",
      "Pic: 0054\n",
      "Pic: 0055\n",
      "Pic: 0056\n",
      "Pic: 0057\n",
      "Pic: 0058\n",
      "Pic: 0059\n",
      "Pic: 0060\n",
      "Pic: 0061\n",
      "Pic: 0062\n",
      "Pic: 0063\n",
      "Pic: 0064\n",
      "Pic: 0065\n",
      "Pic: 0066\n",
      "Pic: 0067\n",
      "Pic: 0068\n"
     ]
    }
   ],
   "source": [
    "# Transform all the pic\n",
    "from registration import ICPSVD\n",
    "\n",
    "transformations = []\n",
    "trajectories = []\n",
    "trajectories.append([0,0,0,1])\n",
    "\n",
    "for index in range(first_image + 1, image_number + 1):\n",
    "    print(\"Pic: {0:04d}\".format(index))\n",
    "    # Load point cloud and preprocessing\n",
    "    source, source_down, source_fpfh = prepare_dataset(index, voxel_size)\n",
    "    \n",
    "    # Global registration\n",
    "    result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "    trans_init = result_ransac.transformation\n",
    "\n",
    "    # Local registration\n",
    "    reg_SVD = ICPSVD(target_down, source_down, trans_init, threshold, max_iteration)\n",
    "\n",
    "    # Update the transformations list and transform the current pcd to G_0\n",
    "    transformations.append(reg_SVD)\n",
    "    t = np.identity(4)\n",
    "    for trans in transformations:\n",
    "        t = np.dot(t, trans)\n",
    "    # transofrm the source to G_0\n",
    "    s = copy.deepcopy(source)\n",
    "    s.transform(t)\n",
    "    # Trajectory\n",
    "    transition = np.append(reg_SVD[0:3,3], 1)\n",
    "    trajectories.append(np.dot(t, transition))\n",
    "    \n",
    "    # Aggregate the result\n",
    "    aggr_pcd += s\n",
    "    \n",
    "    target = source\n",
    "    target_down = source_down\n",
    "    target_fpfh = source_fpfh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "aggr_pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "aggr_pcd_down = aggr_pcd.voxel_down_sample(voxel_size / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55311a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([aggr_pcd_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d2550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the roof\n",
    "no_roof_pcd = copy.deepcopy(aggr_pcd_down)\n",
    "pts = np.asarray(no_roof_pcd.points)\n",
    "crs = np.asarray(no_roof_pcd.colors)\n",
    "valid = pts[:,1] < 0\n",
    "\n",
    "no_roof_pcd.points = o3d.utility.Vector3dVector(pts[valid])\n",
    "no_roof_pcd.colors = o3d.utility.Vector3dVector(crs[valid])\n",
    "# o3d.visualization.draw_geometries([no_roof_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ec6e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "lines = []\n",
    "line_index = 1\n",
    "\n",
    "with open(file_path + \"GT_pose.txt\", \"r\") as fp:\n",
    "    line= fp.readline()\n",
    "    x, y, z, rw, rx, ry, rz= line.split(\" \")\n",
    "    x0 = float(x) \n",
    "    y0 = float(y)\n",
    "    z0 = float(z)\n",
    "    points.append([(x0 - x0), (y0 - y0), (z0 - z0)])\n",
    "    line= fp.readline()\n",
    "    while line:\n",
    "        x, y, z, rw, rx, ry, rz= line.split(\" \")\n",
    "        x = float(x) - x0\n",
    "        y = float(y) - y0\n",
    "        z = float(z) - z0\n",
    "        points.append([x*0.0255, y*0.0255, z*0.0255])\n",
    "        lines.append([line_index - 1, line_index])\n",
    "        line_index += 1\n",
    "        line = fp.readline()\n",
    "print(len(points))\n",
    "fp.close()\n",
    "\n",
    "colors = [[1, 0, 0] for i in range(len(lines))]\n",
    "gt_line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "gt_line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([gt_line_set, no_roof_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7a586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "lines = []\n",
    "line_index = 0\n",
    "# points.append(p)\n",
    "for tra in trajectories:\n",
    "    # multiply by transformation\n",
    "#     p += -trans[0:3,3]\n",
    "    tra = np.dot([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]], tra)\n",
    "    points.append(tra[0:3])\n",
    "    lines.append([line_index, line_index + 1])\n",
    "    line_index += 1\n",
    "del lines[-1]\n",
    "\n",
    "colors = [[0, 0, 1] for i in range(len(lines))]\n",
    "icp_line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines),\n",
    ")\n",
    "icp_line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "# o3d.visualization.draw_geometries([icp_line_set, no_roof_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511abe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([gt_line_set, icp_line_set, no_roof_pcd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
